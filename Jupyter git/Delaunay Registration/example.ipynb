{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b6fd15a",
   "metadata": {},
   "source": [
    "# Multi-channel Delaunay Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76ddb5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import tifffile as tiff\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from cpselect.cpselect import cpselect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8f403f",
   "metadata": {},
   "source": [
    "Configure the settings below. \n",
    "\n",
    "*The tif files don't need to have the same dimensions or resolution. Additionally, the script has been tested on both 8bit & 16bit files.\n",
    "\n",
    "*The ref_chnl params indicate which slice in each tif stack/image to use for the moving and target image. Since live is typically a single frame, tar_ref_chnl = 0. In this example, the 5ch_hcr file contains the mCherry reference in the 2nd slice, so mov_ref_chnl = 1.\n",
    "\n",
    "*(These are the only parameters you need to change)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49a872b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file paths\n",
    "params = {\n",
    "    'output_dir': r\"C:\\Users\\emricklab\\Desktop\",\n",
    "    'output_filename': r\"stack.tiff\",\n",
    "    'moving': r\"C:\\Users\\emricklab\\Desktop\\Hcr_5ch_crop.tif\",\n",
    "    'mov_ref_chnl': 1,\n",
    "    'target': r\"C:\\Users\\emricklab\\Desktop\\Live.tif\",\n",
    "    'tar_ref_chnl': 0  # \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901ee8b2",
   "metadata": {},
   "source": [
    "Import the target & reference mCherry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dd18eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the moving stack\n",
    "moving = []\n",
    "ret, moving = cv2.imreadmulti(mats=moving, filename=params['moving'], flags=cv2.IMREAD_COLOR)\n",
    "\n",
    "# Reading the target image\n",
    "target = []\n",
    "ret2, target = cv2.imreadmulti(mats=target, filename=params['target'], flags=cv2.IMREAD_COLOR)\n",
    "\n",
    "# Select Referance mCherry\n",
    "mcherry_hcr = \"mcherry_hcr.tif\" \n",
    "cv2.imwrite(mcherry_hcr, moving[params['mov_ref_chnl']]) #channel 1 = 2nd slice of tif stack = mcherry ref\n",
    "\n",
    "mcherry_live = \"mcherry_live.tif\" \n",
    "cv2.imwrite(mcherry_live, target[params['tar_ref_chnl']])\n",
    "img2 = cv2.imread(mcherry_live)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f4beb5",
   "metadata": {},
   "source": [
    "Use the cpselect GUI to acquire point-correspondence landmarks. Refer to https://github.com/hofmann-tobias/cpselect for usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afb75dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select landmarks in mcherry_hcr and mcherry_live\n",
    "controlpointlist = cpselect(mcherry_hcr, mcherry_live)\n",
    "\n",
    "# Clean up the temporary filepaths\n",
    "os.remove(mcherry_hcr)\n",
    "os.remove(mcherry_live)\n",
    "\n",
    "#convert controlpointlist to landmark lists for individual hcr/live mcherry\n",
    "landmarks_points = []\n",
    "landmarks_points2 = []\n",
    "\n",
    "for point in controlpointlist:\n",
    "    landmarks_points.append([point['img1_x'], point['img1_y']])\n",
    "    landmarks_points2.append([point['img2_x'], point['img2_y']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d80a49",
   "metadata": {},
   "source": [
    "Create a rectangular bounding box for the pool of landmarks, then convert the landmark lists to int32 points to make calculations faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f6e74c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find minimum and maximum x and y coordinates\n",
    "min_x = min(coord[0] for coord in landmarks_points)\n",
    "max_x = max(coord[0] for coord in landmarks_points)\n",
    "min_y = min(coord[1] for coord in landmarks_points)\n",
    "max_y = max(coord[1] for coord in landmarks_points)\n",
    "\n",
    "# Create corners of the bounding rectangle\n",
    "top_left = [min_x, max_y]\n",
    "top_right = [max_x, max_y]\n",
    "bottom_left = [min_x, min_y]\n",
    "bottom_right = [max_x, min_y]\n",
    "\n",
    "# Add corners to the original list of coordinates\n",
    "landmarks_points.append(top_left)\n",
    "landmarks_points.append(top_right)\n",
    "landmarks_points.append(bottom_left)\n",
    "landmarks_points.append(bottom_right)\n",
    "\n",
    "#REPEAT FOR LANDMARKS IN IMG2\n",
    "min_x = min(coord[0] for coord in landmarks_points2)\n",
    "max_x = max(coord[0] for coord in landmarks_points2)\n",
    "min_y = min(coord[1] for coord in landmarks_points2)\n",
    "max_y = max(coord[1] for coord in landmarks_points2)\n",
    "\n",
    "top_left = [min_x, max_y]\n",
    "top_right = [max_x, max_y]\n",
    "bottom_left = [min_x, min_y]\n",
    "bottom_right = [max_x, min_y]\n",
    "\n",
    "landmarks_points2.append(top_left)\n",
    "landmarks_points2.append(top_right)\n",
    "landmarks_points2.append(bottom_left)\n",
    "landmarks_points2.append(bottom_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec6d89d",
   "metadata": {},
   "source": [
    "Run the Delaunay registration algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "875cc36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_index_nparray(nparray):\n",
    "    index = None\n",
    "    for num in nparray[0]:\n",
    "        index = num\n",
    "        break\n",
    "    return index\n",
    "\n",
    "#IMG2 = FIXED\n",
    "img2_gray = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "warped_images = []\n",
    "#LOOP PROCESSING FOR EACH CHANNEL IN MOVING\n",
    "for image in moving: \n",
    "    \n",
    "    #GENERATE POINTS ARRAY FROM LANDMARK LIST\n",
    "    points = np.array(landmarks_points, np.int32)\n",
    "    points2 = np.array(landmarks_points2, np.int32)\n",
    "\n",
    "    #GENERATE RECTANGULAR CONVEXHULLS\n",
    "    convexhull = cv2.convexHull(points)\n",
    "    convexhull2 = cv2.convexHull(points2)\n",
    "    \n",
    "    #Create empty image to place warp on\n",
    "    height, width, channels = img2.shape\n",
    "    img2_new_face = np.zeros((height, width, channels), np.uint8)\n",
    "    \n",
    "    #IMG 1 = MOVING\n",
    "    img = image\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    mask = np.zeros_like(img_gray)\n",
    "    \n",
    "    # Face 1\n",
    "    cv2.fillConvexPoly(mask, convexhull, 255)\n",
    "    face_image_1 = cv2.bitwise_and(img, img, mask=mask)\n",
    "    \n",
    "    # Delaunay triangulation\n",
    "    rect = cv2.boundingRect(convexhull)\n",
    "    subdiv = cv2.Subdiv2D(rect)\n",
    "    subdiv.insert(landmarks_points)\n",
    "    triangles = subdiv.getTriangleList()\n",
    "    triangles = np.array(triangles, dtype=np.int32)\n",
    "\n",
    "    indexes_triangles = []\n",
    "    for t in triangles:\n",
    "        pt1 = (t[0], t[1])\n",
    "        pt2 = (t[2], t[3])\n",
    "        pt3 = (t[4], t[5])\n",
    "\n",
    "\n",
    "        index_pt1 = np.where((points == pt1).all(axis=1))\n",
    "        index_pt1 = extract_index_nparray(index_pt1)\n",
    "\n",
    "        index_pt2 = np.where((points == pt2).all(axis=1))\n",
    "        index_pt2 = extract_index_nparray(index_pt2)\n",
    "\n",
    "        index_pt3 = np.where((points == pt3).all(axis=1))\n",
    "        index_pt3 = extract_index_nparray(index_pt3)\n",
    "\n",
    "        if index_pt1 is not None and index_pt2 is not None and index_pt3 is not None:\n",
    "            triangle = [index_pt1, index_pt2, index_pt3]\n",
    "            indexes_triangles.append(triangle)\n",
    "            \n",
    "    #FIX LINE ISSUE: mask the boundaries\n",
    "    lines_space_mask = np.zeros_like(img_gray)\n",
    "    lines_space_new_face = np.zeros_like(img2)\n",
    "    \n",
    "    \n",
    "    # Triangulation of both faces\n",
    "    for triangle_index in indexes_triangles:\n",
    "        # Triangulation of the first face\n",
    "        tr1_pt1 = landmarks_points[triangle_index[0]]\n",
    "        tr1_pt2 = landmarks_points[triangle_index[1]]\n",
    "        tr1_pt3 = landmarks_points[triangle_index[2]]\n",
    "        triangle1 = np.array([tr1_pt1, tr1_pt2, tr1_pt3], np.int32)\n",
    "\n",
    "\n",
    "        rect1 = cv2.boundingRect(triangle1)\n",
    "        (x, y, w, h) = rect1\n",
    "        cropped_triangle = img[y: y + h, x: x + w]\n",
    "        cropped_tr1_mask = np.zeros((h, w), np.uint8)\n",
    "\n",
    "\n",
    "        points = np.array([[tr1_pt1[0] - x, tr1_pt1[1] - y],\n",
    "                           [tr1_pt2[0] - x, tr1_pt2[1] - y],\n",
    "                           [tr1_pt3[0] - x, tr1_pt3[1] - y]], np.int32)\n",
    "\n",
    "        cv2.fillConvexPoly(cropped_tr1_mask, points, 255)\n",
    "\n",
    "        #convert floats to ints\n",
    "        tr1_pt1 = [int(x) for x in tr1_pt1]\n",
    "        tr1_pt2 = [int(x) for x in tr1_pt1]\n",
    "        tr1_pt3 = [int(x) for x in tr1_pt1]\n",
    "\n",
    "        # Lines space\n",
    "        cv2.line(lines_space_mask, tr1_pt1, tr1_pt2, 255)\n",
    "        cv2.line(lines_space_mask, tr1_pt2, tr1_pt3, 255)\n",
    "        cv2.line(lines_space_mask, tr1_pt1, tr1_pt3, 255)\n",
    "        lines_space = cv2.bitwise_and(img, img, mask=lines_space_mask)\n",
    "\n",
    "        # Triangulation of second face\n",
    "        tr2_pt1 = landmarks_points2[triangle_index[0]]\n",
    "        tr2_pt2 = landmarks_points2[triangle_index[1]]\n",
    "        tr2_pt3 = landmarks_points2[triangle_index[2]]\n",
    "        triangle2 = np.array([tr2_pt1, tr2_pt2, tr2_pt3], np.int32)\n",
    "\n",
    "\n",
    "        rect2 = cv2.boundingRect(triangle2)\n",
    "        (x, y, w, h) = rect2\n",
    "\n",
    "        cropped_tr2_mask = np.zeros((h, w), np.uint8)\n",
    "\n",
    "        points2 = np.array([[tr2_pt1[0] - x, tr2_pt1[1] - y],\n",
    "                            [tr2_pt2[0] - x, tr2_pt2[1] - y],\n",
    "                            [tr2_pt3[0] - x, tr2_pt3[1] - y]], np.int32)\n",
    "\n",
    "        cv2.fillConvexPoly(cropped_tr2_mask, points2, 255)\n",
    "\n",
    "        # Warp triangles\n",
    "        points = np.float32(points)\n",
    "        points2 = np.float32(points2)\n",
    "        M = cv2.getAffineTransform(points, points2)\n",
    "        warped_triangle = cv2.warpAffine(cropped_triangle, M, (w, h))\n",
    "        warped_triangle = cv2.bitwise_and(warped_triangle, warped_triangle, mask=cropped_tr2_mask)\n",
    "\n",
    "        # Reconstructing destination face\n",
    "        img2_new_face_rect_area = img2_new_face[y: y + h, x: x + w]\n",
    "        img2_new_face_rect_area_gray = cv2.cvtColor(img2_new_face_rect_area, cv2.COLOR_BGR2GRAY)\n",
    "        _, mask_triangles_designed = cv2.threshold(img2_new_face_rect_area_gray, 1, 255, cv2.THRESH_BINARY_INV)\n",
    "        warped_triangle = cv2.bitwise_and(warped_triangle, warped_triangle, mask=mask_triangles_designed)\n",
    "\n",
    "        img2_new_face_rect_area = cv2.add(img2_new_face_rect_area, warped_triangle)\n",
    "        img2_new_face[y: y + h, x: x + w] = img2_new_face_rect_area\n",
    "        \n",
    "    \n",
    "    warped_images.append(img2_new_face)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1397097c",
   "metadata": {},
   "source": [
    "Save the registered file to specified output dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ab6ac83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIFF stack saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the images along the channel axis\n",
    "stack = np.stack(warped_images, axis=0)\n",
    "\n",
    "# Save the stack as a multi-channel TIFF\n",
    "output_path = os.path.join(params['output_dir'], params['output_filename'])\n",
    "tiff.imsave(output_path, stack, planarconfig='contig')\n",
    "\n",
    "print(\"TIFF stack saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "del_reg",
   "language": "python",
   "name": "del_reg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
